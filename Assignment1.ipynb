{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DIgM6C9HYUhm"
   },
   "source": [
    "# Context-sensitive Spelling Correction\n",
    "\n",
    "The goal of the assignment is to implement context-sensitive spelling correction. The input of the code will be a set of text lines and the output will be the same lines with spelling mistakes fixed.\n",
    "\n",
    "Submit the solution of the assignment to Moodle as a link to your GitHub repository containing this notebook.\n",
    "\n",
    "Useful links:\n",
    "- [Norvig's solution](https://norvig.com/spell-correct.html)\n",
    "- [Norvig's dataset](https://norvig.com/big.txt)\n",
    "- [Ngrams data](https://www.ngrams.info/download_coca.asp)\n",
    "\n",
    "Grading:\n",
    "- 60 points - Implement spelling correction\n",
    "- 20 points - Justify your decisions\n",
    "- 20 points - Evaluate on a test set\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "x-vb8yFOGRDF"
   },
   "source": [
    "## Implement context-sensitive spelling correction\n",
    "\n",
    "Your task is to implement context-sensitive spelling corrector using N-gram language model. The idea is to compute conditional probabilities of possible correction options. For example, the phrase \"dking sport\" should be fixed as \"doing sport\" not \"dying sport\", while \"dking species\" -- as \"dying species\".\n",
    "\n",
    "The best way to start is to analyze [Norvig's solution](https://norvig.com/spell-correct.html) and [N-gram Language Models](https://web.stanford.edu/~jurafsky/slp3/3.pdf).\n",
    "\n",
    "When solving this task, we expect you'll face (and successfully deal with) some problems or make up the ideas of the model improvement. Some of them are: \n",
    "\n",
    "- solving a problem of n-grams frequencies storing for a large corpus;\n",
    "- taking into account keyboard layout and associated misspellings;\n",
    "- efficiency improvement to make the solution faster;\n",
    "- ...\n",
    "\n",
    "Please don't forget to describe such cases, and what you decided to do with them, in the Justification section.\n",
    "\n",
    "##### IMPORTANT:  \n",
    "Your project should not be a mere code copy-paste from somewhere. You must provide:\n",
    "- Your implementation\n",
    "- Analysis of why the implemented approach is suggested\n",
    "- Improvements of the original approach that you have chosen to implement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Corrected phrase: ding sport\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "from collections import defaultdict, Counter\n",
    "\n",
    "def tokenize(text):\n",
    "    return re.findall(r'\\w+', text.lower())\n",
    "\n",
    "def generate_candidates(word):\n",
    "    letters = 'abcdefghijklmnopqrstuvwxyz'\n",
    "    splits = [(word[:i], word[i:]) for i in range(len(word) + 1)]\n",
    "    deletes = [L + R[1:] for L, R in splits if R]\n",
    "    transposes = [L + R[1] + R[0] + R[2:] for L, R in splits if len(R) > 1]\n",
    "    replaces = [L + c + R[1:] for L, R in splits if R for c in letters]\n",
    "    inserts = [L + c + R for L, R in splits for c in letters]\n",
    "    candidates = set(deletes + transposes + replaces + inserts)\n",
    "    return candidates\n",
    "\n",
    "def filter_candidates(candidates, vocabulary):\n",
    "    return [c for c in candidates if c in vocabulary]\n",
    "\n",
    "def phrase_probability(phrase, ngram_model, n):\n",
    "    tokens = tokenize(phrase)\n",
    "    probability = 1.0\n",
    "    for i in range(n-1, len(tokens)):\n",
    "        context = tuple(tokens[i-n+1:i])\n",
    "        word = tokens[i]\n",
    "        if context in ngram_model and word in ngram_model[context]:\n",
    "            probability *= ngram_model[context][word] / sum(ngram_model[context].values())\n",
    "        else:\n",
    "            probability *= 0.0001\n",
    "    return probability\n",
    "\n",
    "def hybrid_correct_spelling(phrase, bigram_model, fivegram_model, vocabulary):\n",
    "    tokens = tokenize(phrase)\n",
    "    corrected_phrase = []\n",
    "    for i, token in enumerate(tokens):\n",
    "        if token in vocabulary:\n",
    "            corrected_phrase.append(token)\n",
    "        else:\n",
    "            candidates = generate_candidates(token)\n",
    "            valid_candidates = filter_candidates(candidates, vocabulary)\n",
    "            if not valid_candidates:\n",
    "                corrected_phrase.append(token)\n",
    "                continue\n",
    "            if i > 0:\n",
    "                prev_word = tokens[i-1]\n",
    "                bigram_candidates = [(c, bigram_model[prev_word].get(c, 0)) for c in valid_candidates]\n",
    "                fivegram_candidates = [(c, phrase_probability(' '.join(tokens[:i] + [c] + tokens[i+1:]), fivegram_model, 5)) for c in valid_candidates]\n",
    "                combined_candidates = [(c, (bg_score + fg_score) / 2) for (c, bg_score), (_, fg_score) in zip(bigram_candidates, fivegram_candidates)]\n",
    "                best_candidate = max(combined_candidates, key=lambda x: x[1])[0]\n",
    "            else:\n",
    "                best_candidate = max(valid_candidates, key=lambda c: phrase_probability(' '.join(tokens[:i] + [c] + tokens[i+1:]), fivegram_model, 5))\n",
    "            corrected_phrase.append(best_candidate)\n",
    "    return ' '.join(corrected_phrase)\n",
    "\n",
    "bigram_model = defaultdict(Counter)\n",
    "with open('bigrams (2).txt', 'r', encoding='latin1') as f:\n",
    "    for line in f:\n",
    "        parts = line.strip().split('\\t')\n",
    "        if len(parts) == 3:\n",
    "            freq, word1, word2 = parts\n",
    "            bigram_model[word1][word2] = int(freq)\n",
    "\n",
    "fivegram_model = defaultdict(Counter)\n",
    "with open('fivegrams (2).txt', 'r', encoding='latin1') as f:\n",
    "    for line in f:\n",
    "        parts = line.strip().split('\\t')\n",
    "        if len(parts) >= 6:\n",
    "            freq, *words = parts\n",
    "            context = tuple(words[:-1])\n",
    "            word = words[-1]\n",
    "            fivegram_model[context][word] = int(freq)\n",
    "\n",
    "vocabulary = set()\n",
    "with open('bigrams (2).txt', 'r', encoding='latin1') as f:\n",
    "    for line in f:\n",
    "        parts = line.strip().split('\\t')\n",
    "        if len(parts) == 3:\n",
    "            word1, word2 = parts[1], parts[2]\n",
    "            vocabulary.add(word1)\n",
    "            vocabulary.add(word2)\n",
    "\n",
    "with open('fivegrams (2).txt', 'r', encoding='latin1') as f:\n",
    "    for line in f:\n",
    "        parts = line.strip().split('\\t')\n",
    "        if len(parts) >= 6:\n",
    "            *words, _ = parts[1:]\n",
    "            vocabulary.update(words)\n",
    "\n",
    "misspelled_phrase = \"dking sport\"\n",
    "corrected_phrase = hybrid_correct_spelling(misspelled_phrase, bigram_model, fivegram_model, vocabulary)\n",
    "print(f\"Corrected phrase: {corrected_phrase}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oML-5sJwGRLE"
   },
   "source": [
    "## Justify your decisions\n",
    "\n",
    "Write down justificaitons for your implementation choices. For example, these choices could be:\n",
    "- Which ngram dataset to use\n",
    "- Which weights to assign for edit1, edit2 or absent words probabilities\n",
    "- Beam search parameters\n",
    "- etc."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6Xb_twOmVsC6"
   },
   "source": [
    "Why Bigrams and Fivegrams?\n",
    "\n",
    "Bigrams: Bigrams capture local context, which is useful for correcting misspelled words based on the previous word. For example, in the phrase \"dking sport\", the bigram model helps prioritize \"doing sport\" over \"dying sport\" because \"doing sport\" is more likely in the corpus.\n",
    "Fivegrams: Fivegrams capture longer-range dependencies, which are useful for correcting phrases with more complex context. For example, in the phrase \"dking species\", the fivegram model helps prioritize \"dying species\" over \"doing species\" because \"dying species\" is more likely in the corpus.\n",
    "\n",
    "Why Use a Hybrid Approach?\n",
    "\n",
    "The hybrid approach combines the strengths of both bigram and fivegram models:\n",
    "Bigram Model: Provides local context (e.g., the previous word).\n",
    "Fivegram Model: Provides longer-range context (e.g., the previous four words).\n",
    "By combining the probabilities from both models, the system can make more accurate corrections in a variety of contexts.\n",
    "\n",
    "Challenge: Context Sensitivity\n",
    "\n",
    "The model must consider both local and global context to make accurate corrections.\n",
    "Solution: Use a hybrid approach that combines bigram and fivegram models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "46rk65S4GRSe"
   },
   "source": [
    "## Evaluate on a test set\n",
    "\n",
    "Your task is to generate a test set and evaluate your work. You may vary the noise probability to generate different datasets with varying compexity (or just take another dataset). Compare your solution to the Norvig's corrector, and report the accuracies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total phrases extracted: 2220962\n",
      "Test dataset saved to test_data.txt\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import random\n",
    "from collections import defaultdict, Counter\n",
    "\n",
    "def introduce_typos(word, num_typos=1):\n",
    "    letters = 'abcdefghijklmnopqrstuvwxyz'\n",
    "    for _ in range(num_typos):\n",
    "        typo_type = random.choice(['delete', 'replace', 'swap'])\n",
    "        pos = random.randint(0, len(word) - 1)\n",
    "        if typo_type == 'delete' and len(word) > 1:\n",
    "            word = word[:pos] + word[pos+1:]\n",
    "        elif typo_type == 'replace':\n",
    "            word = word[:pos] + random.choice(letters) + word[pos+1:]\n",
    "        elif typo_type == 'swap' and len(word) > 1:\n",
    "            if pos == len(word) - 1:\n",
    "                pos -= 1\n",
    "            word = word[:pos] + word[pos+1] + word[pos] + word[pos+2:]\n",
    "    return word\n",
    "\n",
    "def extract_phrases(file_path, encoding='latin1'):\n",
    "    phrases = []\n",
    "    with open(file_path, 'r', encoding=encoding) as f:\n",
    "        for line in f:\n",
    "            parts = line.strip().split('\\t')\n",
    "            if len(parts) >= 2:\n",
    "                phrase = ' '.join(parts[1:])\n",
    "                phrases.append(phrase)\n",
    "    return phrases\n",
    "\n",
    "def generate_misspelled_phrases(phrases, num_typos=1):\n",
    "    test_cases = []\n",
    "    for phrase in phrases:\n",
    "        words = phrase.split()\n",
    "        misspelled_words = [introduce_typos(word, num_typos) for word in words]\n",
    "        misspelled_phrase = ' '.join(misspelled_words)\n",
    "        test_cases.append((misspelled_phrase, phrase))\n",
    "    return test_cases\n",
    "\n",
    "def save_test_data(test_cases, file_path):\n",
    "    with open(file_path, 'w', encoding='utf-8') as f:\n",
    "        for misspelled, correct in test_cases:\n",
    "            f.write(f\"{misspelled}\\t{correct}\\n\")\n",
    "\n",
    "bigram_file = 'bigrams (2).txt'\n",
    "coca_file = 'coca_all_links (2).txt'\n",
    "fivegram_file = 'fivegrams (2).txt'\n",
    "output_file = 'test_data.txt'\n",
    "bigram_phrases = extract_phrases(bigram_file)\n",
    "coca_phrases = extract_phrases(coca_file)\n",
    "fivegram_phrases = extract_phrases(fivegram_file)\n",
    "all_phrases = bigram_phrases + coca_phrases + fivegram_phrases\n",
    "print(f\"Total phrases extracted: {len(all_phrases)}\")\n",
    "test_cases = generate_misspelled_phrases(all_phrases, num_typos=1)\n",
    "save_test_data(test_cases, output_file)\n",
    "print(f\"Test dataset saved to {output_file}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 8.02%\n"
     ]
    }
   ],
   "source": [
    "def load_test_data(file_path):\n",
    "    test_cases = []\n",
    "    with open(file_path, 'r', encoding='utf-8') as f:\n",
    "        for line in f:\n",
    "            misspelled, correct = line.strip().split('\\t')\n",
    "            test_cases.append((misspelled, correct))\n",
    "    return test_cases\n",
    "\n",
    "def evaluate_model(test_cases, correct_spelling, bigram_model, fivegram_model, vocabulary):\n",
    "    correct_count = 0\n",
    "    for misspelled, correct in test_cases:\n",
    "        corrected_phrase = correct_spelling(misspelled, bigram_model, fivegram_model, vocabulary)\n",
    "        if corrected_phrase == correct:\n",
    "            correct_count += 1\n",
    "    accuracy = correct_count / len(test_cases)\n",
    "    print(f\"Accuracy: {accuracy * 100:.2f}%\")\n",
    "\n",
    "test_cases = load_test_data('test_data.txt')\n",
    "evaluate_model(test_cases, correct_spelling, bigram_model, fivegram_model, vocabulary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate_model(test_cases, correct_spelling, bigram_model, fivegram_model, vocabulary)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Useful resources (also included in the archive in moodle):\n",
    "\n",
    "1. [Possible dataset with N-grams](https://www.ngrams.info/download_coca.asp)\n",
    "2. [Damerau–Levenshtein distance](https://en.wikipedia.org/wiki/Damerau–Levenshtein_distance#:~:text=Informally%2C%20the%20Damerau–Levenshtein%20distance,one%20word%20into%20the%20other.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
